{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patriciacs99/WeaponDetectionYOLOv5/blob/main/WeaponDetectionYOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nlu9T9k8E5u"
      },
      "source": [
        "# üî´ Detecci√≥n de armas de fuego con YOLOV5 \n",
        "*Autor: Patricia Corral Sanz*\n",
        "\n",
        "> En este proyecto se han utilizado los siguientes snipets para detectar armas de fuego y clasificarlas en armas largas (escopetas, fusiles, ametralladoras y francotiradores) y cortas (pistolas y rev√≥lveres).  \n",
        "Para los experimentos realizados se ejecutar√°n las celdas necesarias para cada uno de ellos en funci√≥n del objetivo del mismo. En cada caso cambiando los valores necesarios tal y como se indica en este cuaderno.  \n",
        "Se utilizar√°n distintos datasets que pueden encontrarse en:  \n",
        "https://drive.google.com/drive/folders/15O3lpCT-JYyuhEc5WftPzr0vCELjLPSS?usp=drive_link  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7alvtOhBfx5"
      },
      "outputs": [],
      "source": [
        "#importar librer√≠as\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import glob\n",
        "import re\n",
        "import time\n",
        "from pathlib import Path\n",
        "import itertools\n",
        "from IPython.display import Image,display\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Comprobar GPU asignada\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "uN0ORk4dXP4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_O69Z_qfIa8"
      },
      "source": [
        "##Preparar de los datos y Yolov5\n",
        "\n",
        "\n",
        "\n",
        "> En este apartado accederemos a Google Drive, donde tendremos organizados los datasets a utilizar en los experimentos.   \n",
        "Clonaremos el repositorio de YOLOv5 de Ultralytics para poder trabajar con √©l e instalaremos los requisitos del mismo.  \n",
        "Descargaremos tambi√©n los modelos de YOLOv5 con pesos pre-entrenados con el dataset de COCO que vayamos a utilizar. En nuestro caso, solo utilizaremos YOLOv5s y YOLOv5m.  \n",
        "\n",
        "‚ö† *Como resultado de la ejecuci√≥n de los ficheros de YOLOv5 (train.py,detect.py y val.py) se generar√° en el directorio de YOLOv5 que hemos clonado una carpeta \"runs\" donde encontraremos los resultados de las ejecuciones.*\n",
        "\n",
        "\n",
        "\n",
        "> En el fichero data.yaml se especifican las rutas a las im√°genes de test, validaci√≥n y entrenamiento de nuestro dataset. Por tanto, antes de ejecutar las celdas es necesario asegurarse de que el fichero contiene las rutas correctas. De lo contrario YOLOv5 no encontrar√° las im√°genes con las que trabajar.  \n",
        "* train: ../ruta_imagenes_entrenamiento\n",
        "* val:   ../ruta_imagenes_validacion\n",
        "* test:  ../ruta_imagenes_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9QN-80oVxP8"
      },
      "outputs": [],
      "source": [
        "#conectar con google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU799ikTW_fx"
      },
      "outputs": [],
      "source": [
        "#clonar YOLO V5 \n",
        "%cd content\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLulDOv8Q3hI"
      },
      "outputs": [],
      "source": [
        "#Instalar YOLOv5\n",
        "%cd /content/yolov5\n",
        "%pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb6of7pXXIU0"
      },
      "outputs": [],
      "source": [
        "# Descargar modelo con pesos preentrenado\n",
        "'''\n",
        "  Modelos a probar:\n",
        "    - yolov5s.pt\n",
        "    - yolov5m.pt\n",
        "    - yolov5l.pt\n",
        "    - yolov5x.pt\n",
        "'''\n",
        "# Sustituir \"yolov5m.pt\" en el link por el nombre del modelo a descargar\n",
        "!wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5m.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJZ8-j-pHONy"
      },
      "source": [
        "## üëü Entrenar modelo\n",
        "\n",
        "\n",
        "> Entrenaremos el modelo para nuestro caso en particular: detectar armas de fuego cortas y largas.  \n",
        "En las siguientes celdas, deben sustituirse por sus correspondientes rutas: \n",
        "*   **ruta_fichero_configuracion**: ruta al fichero yaml del dataset utilizado.\n",
        "*   **ruta_pesos_modelo_YOLOv5**: ruta al modelo con los pesos pre-entrenados previamente descargado. \n",
        "*   **ruta_directorio_resultados**: ruta al directorio donde se han generado los resultados.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACbed_Re711-"
      },
      "outputs": [],
      "source": [
        "!python train.py --img 416 --batch 32 --epochs 100 --data ruta_fichero_configuracion --weights ruta_pesos_modelo_YOLOv5   --name \"resultados_entrenamiento\" --nosave "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQkYUq41syHy"
      },
      "outputs": [],
      "source": [
        "#Descargar resultados entrenamiento\n",
        "from google.colab import files\n",
        "\n",
        "!zip -r train_results_yolov5.zip ruta_directorio_resultados/resultados_entrenamiento\n",
        "files.download('train_results_yolov5.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0L0b39uM2--"
      },
      "source": [
        "### Resultados entrenamiento con Tensorboard\n",
        "\n",
        "\n",
        "> Ejecutaremos Tensorboard para visualizar las gr√°ficas resultado del entrenamiento.  \n",
        "Sustituir:  \n",
        "*   **directorio_entrenamiento**: ruta del diretorio donde se han generado los resultados del entrenamiento.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89rT52JvM56x"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI2vQ-xn3j7N"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir directorio_entrenamiento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkO_f-goz8_i"
      },
      "source": [
        "## üéØ Inferencia \n",
        "\n",
        "> Se usar√°n los pesos del modelo entrenado para detectar y clasificar armas en nuevas im√°genes de test que no ha visto el modelo anteriormente.  En las siguientes celdas, deben sustituirse por sus correspondientes rutas:  \n",
        "*   **ruta_imagenes_test**: ruta a las imagenes de test del dataset.\n",
        "*   **ruta_pesos**: ruta a los pesos generados en el entrenamiento.\n",
        "*   **ruta_detecciones**: ruta del directorio donde se han generados los resultados de la inferencia.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xehIJ1w5z8U5"
      },
      "outputs": [],
      "source": [
        "!python detect.py --source ruta_imagenes_test --weights ruta_pesos --img 416  --save-txt #--save-crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YX343_Ub0M0C"
      },
      "outputs": [],
      "source": [
        "#Mostrar las imagenes de test con las detecciones\n",
        "for imageName in glob.glob(\"ruta_detecciones/*.jpg\"):\n",
        "  display(Image(filename=imageName))\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1gstUP3-JTF"
      },
      "outputs": [],
      "source": [
        "#Descargar resultados detect\n",
        "from google.colab import files\n",
        "\n",
        "!zip -r train_detect_yolov5.zip ruta_detecciones\n",
        "files.download('train_detect_yolov5.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZBV-H0IPmOA"
      },
      "source": [
        "## üìà Evaluacion\n",
        "\n",
        "\n",
        ">   \n",
        "\n",
        "> Extraeremos las m√©tricas de el modelo sobre las nuevas im√°genes de test para poder evaluar su desempe√±o.  \n",
        "En las siguientes celdas, deben sustituirse por sus correspondientes rutas: \n",
        "*   **ruta_fichero_configuracion**: ruta al fichero yaml del dataset utilizado.\n",
        "*   **ruta_pesos**: ruta donde se encuentra el fichero con los pesos resultado del entrenamiento del modelo.\n",
        "*   **ruta_directorio_resultados**: ruta del directorio donde se han generado los resultados de la ejecuci√≥n del fichero val.py.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CXnggn7kPrP"
      },
      "outputs": [],
      "source": [
        "!python val.py --weights ruta_pesos --data ruta_fichero_configuracion --workers 0 --img 416 --save-txt --conf-thres 0.5 --task test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFsdEvaquFum"
      },
      "outputs": [],
      "source": [
        "#Descargar resultados entrenamiento\n",
        "from google.colab import files\n",
        "\n",
        "!zip -r train_metrics_yolov5.zip ruta_directorio_resultados\n",
        "files.download('train_metrics_yolov5.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## üìë C√≥digos complementarios\n",
        "\n",
        "\n",
        "> Los siguientes c√≥digos han resultado √∫tiles para la elaboraci√≥n de los experimentos.\n",
        "\n"
      ],
      "metadata": {
        "id": "eLLZhBhyNieQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvrh4RF680Lw"
      },
      "source": [
        "### Intersection Over Union\n",
        "\n",
        "\n",
        ">Aun que YOLO calcula el mismo el IoU, aqu√≠ se calcula para cada imagen las intersecciones para poder dibujarlas en cada imagen.   \n",
        "Al ejecutar las siguientes celdas, se calcula la intersecci√≥n entre la etiqueta real y la detecci√≥n, y se dibuja el Ground Truth sobre la imagen que contiene la detecci√≥n para poder visualizar claramente la diferencia. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-pz6NJusKke"
      },
      "outputs": [],
      "source": [
        " #formato: x,y,w,h  ---> formato: x1,y1,x2,y2\n",
        "def rectangulo(box):\n",
        "    box_x1 = box[0] - box[2]/2\n",
        "    box_y1 = box[1] - box[3]/2\n",
        "    box_x2 = box[0] + box[2]/2\n",
        "    box_y2 = box[1] + box[3]/2\n",
        "    return [box_x1,box_y1,box_x2,box_y2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p86zjRKj9_pO"
      },
      "outputs": [],
      "source": [
        "def intersection_over_union(target_bbox,predicted_bbox):\n",
        "   \n",
        "    #formato: x,y,w,h\n",
        "\n",
        "    #Calcular esquinas bboxes\n",
        "    tg = rectangulo(target_bbox)\n",
        "    pred = rectangulo(predicted_bbox)\n",
        "\n",
        "    #Calcular esquinas interseccion\n",
        "    x1 = max(pred[0], tg[0])\n",
        "    y1 = max(pred[1], tg[1])\n",
        "    x2 = min(pred[2], tg[2])\n",
        "    y2 = min(pred[3], tg[3])\n",
        "\n",
        "    #area = w * h\n",
        "    intersection = max(0,(x2 - x1)) * max(0,(y2 - y1))\n",
        "\n",
        "    box1_area = abs((pred[2] - pred[0]) * (pred[3] - pred[1]))\n",
        "    box2_area = abs((tg[2] - tg[0]) * (tg[3] - tg[1]))S\n",
        "\n",
        "    return intersection / (box1_area + box2_area - intersection + 1e-16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C05eBa8oDk4"
      },
      "outputs": [],
      "source": [
        "#Pintar detecciones,IoU,groundTruth\n",
        "\n",
        "predicted = \"/content/yolov5/runs/detect/exp/labels/0205_jpg.rf.eb76fc2a71b61cec8cdf25fd3e51c6cb.txt\"\n",
        "real = \"/content/drive/MyDrive/Deteccion_armas_TFG/Datasets/Customized/WeaponsDataset.v8-weapons_strectch_oclussionsomited.yolov5pytorch/test/images/0205_jpg.rf.eb76fc2a71b61cec8cdf25fd3e51c6cb.jpg\"\n",
        "\n",
        "#Leer imagen deteccion\n",
        "image = cv2.imread(\"/content/drive/MyDrive/Deteccion_armas_TFG/Datasets/weapons.v2-weapons_blackedges_contrast.yolov5pytorch/test/images/0251_jpg.rf.1d75a35dbae43d7e1f13a8266a5d8726.jpg\")\n",
        "\n",
        "with open(real) as archivo: # Abrimos el fichero con las coordenadas del gt\n",
        "    for linea in archivo:\n",
        "      coord1 =[] # lista que almacena las coordenadas del fichero\n",
        "      clase = linea[0] # sacamos la clase de la deteccion - primer caracter de la linea leida\n",
        "      coord1.append(linea[1:].split()) # Eliminamos ese primer caracter y a√±adimos el resto a la lista \n",
        "      coord1 =list(itertools.chain(*coord1)) # Aplanamos la lista\n",
        "      x=0\n",
        "      for i in coord1: # Castear los valores de string a float\n",
        "            coord1[x]= float(i)\n",
        "            x +=1\n",
        "      coords= [] # Habra que guardar las coordenadas de todas las posibles detecciones para compararlas con el gt\n",
        "      if os.path.exists(predicted): # Si existe el archivo con las detecciones repetimos el proceso para cada deteccion\n",
        "        with open(predicted) as archivo:\n",
        "          for linea in archivo:\n",
        "                coord2 =[]\n",
        "                coord2.append(linea[1:].split())\n",
        "                coord2= list(itertools.chain(*coord2))\n",
        "                x=0\n",
        "                for i in coord2:\n",
        "                        coord2[x]= float(i)\n",
        "                        x +=1\n",
        "                coords.append(coord2)\n",
        "        \n",
        "        ious = [] # Almacenamos las ious\n",
        "        for i in coords:\n",
        "            ious.append(intersection_over_union(i,coord1))\n",
        "        # Nos quedamos con la deteccion con mayor IoU\n",
        "        mayor = ious.index(max(ious)) \n",
        "        deteccion = coords[mayor]\n",
        "      \n",
        "        pred = rectangulo(deteccion)\n",
        "        gt = rectangulo(coord1)\n",
        "        iou = max(ious)\n",
        "\n",
        "      else:\n",
        "        pred = rectangulo([0,0,0,0])\n",
        "        gt = rectangulo(coord1)\n",
        "        iou = 0.000\n",
        "\n",
        "      for i in range(0,4):\n",
        "          gt[i] = int(gt[i]*416)\n",
        "\n",
        "      start_point = tuple(gt[:2])\n",
        "      end_point = tuple(gt[2:])\n",
        "      \n",
        "      #Imprimir rectangulos sobre la imagen de la deteccion\n",
        "      cv2.rectangle(image,start_point,end_point,(0, 255, 0), 4)\n",
        "      \n",
        "      cv2.putText(image, \"IoU: {:.3f}\".format(iou), (gt[0]-10, gt[1]-10),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "      if iou !=0:\n",
        "        cv2.putText(image, \"Class: \"+ clase, (gt[0]+105, gt[1]- 10),\n",
        "              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0, 0), 2)\n",
        "        \n",
        "# Mostrar la imagen con el IoU, la deteccion y el ground truth\n",
        "cv2_imshow(image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tama√±o de las instancias de una imagen \n",
        "\n",
        "\n",
        "> C√≥digo para dividir las im√°genes de test seg√∫n su tama√±o utilizado en el experimento 2.\n",
        "\n"
      ],
      "metadata": {
        "id": "BRwffXFufBeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear 3 directorios para dividir las imagenes\n",
        "os.makedirs(\"dir_peq/images\")\n",
        "os.makedirs(\"dir_peq/labels\")\n",
        "os.makedirs(\"dir_med/images\")\n",
        "os.makedirs(\"dir_med/labels\")\n",
        "os.makedirs(\"dir_gra/images\")\n",
        "os.makedirs(\"dir_gra/labels\")"
      ],
      "metadata": {
        "id": "QbKYhCGSuMoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_origen = \"/content/drive/MyDrive/Deteccion_armas_TFG/Datasets/weapons.v2-weapons_blackedges_contrast.yolov5pytorch/test/images/\"\n",
        "\n",
        "# Directorio imagenes\n",
        "imagenes = glob.glob(\"/content/drive/MyDrive/Deteccion_armas_TFG/Datasets/weapons.v2-weapons_blackedges_contrast.yolov5pytorch/test/images/*.jpg\")\n",
        "\n",
        "dir_gra = \"/content/dir_gra\"\n",
        "dir_med = \"/content/dir_med\"\n",
        "dir_peq = \"/content/dir_peq\"\n",
        "\n",
        "\n",
        "for img in imagenes:\n",
        "  image = cv2.imread(img)\n",
        "  # Tama√±o de la imagen (CUIDADO ESTO EST√Å EN PIXELES)\n",
        "  w = image.shape[0]\n",
        "  h = image.shape[1]\n",
        "  image_size = w*h\n",
        "  real = img.replace(\"/images/\",\"/labels/\",1)\n",
        "  real = real[:-3] + \"txt\"\n",
        "  img_name = re.sub(dir_origen,'',img)\n",
        "  img_label = img_name[:-3] + \"txt\"\n",
        "  print(img_label)\n",
        "  print(img_name)\n",
        "  with open(real) as archivo: # Abrimos el fichero con las coordenadas del gt\n",
        "    lista = archivo.readlines()\n",
        "    num = len(lista)\n",
        "    if num == 1:\n",
        "        linea = lista[0]\n",
        "       \n",
        "        coord1 =[] # lista que almacena las coordenadas del fichero\n",
        "        clase = linea[0] # sacamos la clase de la instancia - primer caracter de la linea leida\n",
        "        coord1.append(linea[1:].split()) # Eliminamos ese primer caracter y a√±adimos el resto a la lista \n",
        "        coord1 =list(itertools.chain(*coord1)) # Aplanamos la lista\n",
        "        x=0\n",
        "        for i in coord1: # Castear los valores de string a float\n",
        "              coord1[x]= float(i)\n",
        "              x +=1\n",
        "        # Sacamos los valores de altura y anchura de las coordenadas extraidas\n",
        "        w1 = coord1[2] * 416\n",
        "        h1 = coord1[3] * 416\n",
        "        # Calculamos el tama√±o de la instancia con dichos valores\n",
        "        instance_size = w1*h1\n",
        "\n",
        "        # Calculamos el porcentaje que ocupa dicha instancia sobre la imagen\n",
        "        percentage_size = instance_size * 100 / image_size\n",
        "        print(\"La instancia ocupa el \"+ str(percentage_size) +\"% de la imagen\")\n",
        "      \n",
        "        if 0 <= percentage_size <= 15: \n",
        "          shutil.copy(img, \"dir_peq/images/\"+ img_name)\n",
        "          shutil.copy(real,\"dir_peq/labels/\"+ img_label)\n",
        "          print(\"Instancia peque\")\n",
        "        elif 16 <= percentage_size <= 35:\n",
        "          shutil.copy(img, \"dir_med/images/\"+  img_name)\n",
        "          shutil.copy(real,\"dir_med/labels/\"+ img_label)\n",
        "          print(\"Instancia mediana\")\n",
        "        else:\n",
        "          shutil.copy(img, \"dir_gra/images/\"+  img_name)\n",
        "          shutil.copy(real,\"dir_gra/labels/\"+ img_label)\n",
        "          print(\"Instancia grande\")\n",
        "      \n",
        "    \n"
      ],
      "metadata": {
        "id": "xcMVjaSDfGVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar im√°genes por tama√±o\n",
        "from google.colab import files\n",
        "\n",
        "!zip -r imagenes_medianas.zip /content/dir_med\n",
        "!zip -r imagenes_peque√±as.zip /content/dir_peq\n",
        "!zip -r imagenes_grandes.zip /content/dir_gra\n",
        "files.download('imagenes_medianas.zip')\n",
        "files.download('imagenes_peque√±as.zip')\n",
        "files.download('imagenes_grandes.zip')"
      ],
      "metadata": {
        "id": "bPZvpWieG3rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modificar valor etiquetas\n",
        "\n",
        ">Si hubiese algun problema porque las clases de los dataset estuviesen cambiadas, este fragmento de c√≥digo modifica el valor de la clase en las etiquetas.  \n",
        "Sustituir **ruta_directorio_etiquetas** por la ruta del diretorio que \n",
        "contiene las etiquetas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lws4kFaVRmsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codigo para reemplazar la clase\n",
        "import glob \n",
        "dir = glob.glob('ruta_directorio_etiquetas/*.txt')\n",
        "\n",
        "for elem in dir:\n",
        " fich1 = open(elem,'r')\n",
        " for line in fich1:\n",
        "      if(line[0] == \"0\"):\n",
        "        data = line.replace(\"0\",\"1\",1)\n",
        "        fich2 = open(elem,'w')\n",
        "        fich2.write(data)\n",
        "        fich2.close()\n",
        "      else:\n",
        "        data = line.replace(\"1\",\"0\",1)\n",
        "        fich2 = open(elem,'w')\n",
        "        fich2.write(data)\n",
        "        fich2.close()\n",
        " fich1.close()\n",
        "\n",
        "         \n",
        "\n"
      ],
      "metadata": {
        "id": "buSfhnQZ4yQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar directorio\n",
        "from google.colab import files\n",
        "\n",
        "!zip -r labels.zip ruta_directorio_etiquetas\n",
        "files.download('labels.zip')"
      ],
      "metadata": {
        "id": "r497aWQz8R7H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KJZ8-j-pHONy",
        "V0L0b39uM2--",
        "IkO_f-goz8_i",
        "8ZBV-H0IPmOA",
        "eLLZhBhyNieQ",
        "bvrh4RF680Lw",
        "BRwffXFufBeC",
        "Lws4kFaVRmsg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}